{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook lets you run predictions against an image classification model trained with `transfer_learning.py` (and bootstrapping from the saved Inception v3 image classification model), in this same directory. See the README in this directory for more information on running the training on a set of photos first.\n",
    "\n",
    "First, some imports and definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import struct\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn import ModeKeys\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "\n",
    "# If you've already downloaded the inception model, and it's elsewhere, \n",
    "# edit this path to reflect that so you don't need to re-download.\n",
    "INCEPTION_MODEL_DIR = '/tmp/imagenet'\n",
    "DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "BOTTLENECK_TENSOR_NAME = 'pool_3/_reshape:0'\n",
    "BOTTLENECK_TENSOR_SIZE = 2048\n",
    "MODEL_INPUT_WIDTH = 299\n",
    "MODEL_INPUT_HEIGHT = 299\n",
    "MODEL_INPUT_DEPTH = 3\n",
    "JPEG_DATA_TENSOR_NAME = 'DecodeJpeg/contents:0'\n",
    "RESIZED_INPUT_TENSOR_NAME = 'ResizeBilinear:0'\n",
    "\n",
    "LABELS_FILENAME = \"output_labels.json\"\n",
    "\n",
    "# Edit IMAGE_PATH_LIST to specify the list of images that you'd like to \n",
    "# categorize against your trained model\n",
    "IMAGE_PATH_LIST = ['prediction_images/knife.jpg',\n",
    "      'prediction_images/puppy.jpg',\n",
    "      'prediction_images/hedgehog.jpg']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edit the following** to point to the model directory in which the trained model that you want to use resides.  If you just did a training run, the directory name will have been printed to STDOUT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace MODEL_DIR with the path to the directory in which your learned model resides.\n",
    "MODEL_DIR = 'path/to/your/trained/model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define some helper functions. You'll find these functions in `transfer_learning.py` also.\n",
    "\n",
    "(In `run_bottleneck_on_image`, note that we're calling `sess.run()` to get the value of the 'bottleneck' layer of the Inception graph, with image data fed to the JPEG_DATA_TENSOR_NAME node.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maybe_download_and_extract():\n",
    "  \"\"\"Download and extract the inception model tar file.\n",
    "  If the pretrained model we're using doesn't already exist, this function\n",
    "  downloads it from the TensorFlow.org website and unpacks it into a directory.\n",
    "  \"\"\"\n",
    "  dest_directory = INCEPTION_MODEL_DIR\n",
    "  if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "  filename = DATA_URL.split('/')[-1]\n",
    "  filepath = os.path.join(dest_directory, filename)\n",
    "  if not os.path.exists(filepath):\n",
    "\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' %\n",
    "                       (filename,\n",
    "                        float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()\n",
    "\n",
    "    filepath, _ = urllib.request.urlretrieve(DATA_URL,\n",
    "                                             filepath,\n",
    "                                             _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "  tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "\n",
    "\n",
    "def create_inception_graph():\n",
    "  \"\"\"\"Creates a graph from saved GraphDef file and returns a Graph object.\n",
    "  \"\"\"\n",
    "  with tf.Session() as sess:\n",
    "    model_filename = os.path.join(\n",
    "        INCEPTION_MODEL_DIR, 'classify_image_graph_def.pb')\n",
    "    with gfile.FastGFile(model_filename, 'rb') as f:\n",
    "      graph_def = tf.GraphDef()\n",
    "      graph_def.ParseFromString(f.read())\n",
    "      bottleneck_tensor, jpeg_data_tensor, resized_input_tensor = (\n",
    "          tf.import_graph_def(graph_def, name='', return_elements=[\n",
    "              BOTTLENECK_TENSOR_NAME, JPEG_DATA_TENSOR_NAME,\n",
    "              RESIZED_INPUT_TENSOR_NAME]))\n",
    "  return sess.graph, bottleneck_tensor, jpeg_data_tensor, resized_input_tensor\n",
    "\n",
    "\n",
    "def run_bottleneck_on_image(sess, image_data, image_data_tensor,\n",
    "                            bottleneck_tensor):\n",
    "  \"\"\"Runs inference on an image to extract the 'bottleneck' summary layer.\n",
    "  \"\"\"\n",
    "  bottleneck_values = sess.run(\n",
    "      bottleneck_tensor,\n",
    "      {image_data_tensor: image_data})\n",
    "  bottleneck_values = np.squeeze(bottleneck_values)\n",
    "  return bottleneck_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to run the image predictions. First, we need to get the 'bottleneck' values, using the graph loaded from the Inception model. Then, we feed that data to our own trained model.\n",
    "`classifier` is a custom Estimator, and we will use its `predict` method. (We'll define the Estimator in a few more cells). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_image_predictions(\n",
    "    classifier, jpeg_data_tensor, bottleneck_tensor, path_list, labels_list):\n",
    "  \"\"\"Use the learned model to make predictions.\"\"\"\n",
    "\n",
    "  if not labels_list:\n",
    "    output_labels_file = os.path.join(MODEL_DIR, LABELS_FILENAME)\n",
    "    if gfile.Exists(output_labels_file):\n",
    "      with open(output_labels_file, 'r') as lfile:\n",
    "        labels_string = lfile.read()\n",
    "        labels_list = json.loads(labels_string)\n",
    "        print(\"labels list: %s\" % labels_list)\n",
    "    else:\n",
    "      print(\"Labels list %s not found\" % output_labels_file)\n",
    "      return None\n",
    "\n",
    "  sess = tf.Session()\n",
    "  bottlenecks = []\n",
    "  print(\"Predicting for images: %s\" % path_list)\n",
    "  for img_path in path_list:\n",
    "    # get bottleneck for an image path.\n",
    "    if not gfile.Exists(img_path):\n",
    "      tf.logging.fatal('File does not exist %s', img_path)\n",
    "    image_data = gfile.FastGFile(img_path, 'rb').read()\n",
    "    bottleneck_values = run_bottleneck_on_image(sess, image_data,\n",
    "                                                jpeg_data_tensor,\n",
    "                                                bottleneck_tensor)\n",
    "    bottlenecks.append(bottleneck_values)\n",
    "  prediction_input = np.array(bottlenecks)\n",
    "  predictions = classifier.predict(x=prediction_input, as_iterable=True)\n",
    "  print(\"Predictions:\")\n",
    "  for _, p in enumerate(predictions):\n",
    "    print(p[\"class\"])\n",
    "    print(p[\"index\"])\n",
    "    print(labels_list[p[\"index\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define the functions used to build the model graph. (Some of these graph nodes are not needed for just prediction, but we'll include them to keep these functions consistent with those in `transfer_learning.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_final_training_ops(\n",
    "    class_count, mode, final_tensor_name,\n",
    "    bottleneck_input, ground_truth_input):\n",
    "  \"\"\"Adds a new softmax and fully-connected layer for training.\n",
    "  \"\"\"\n",
    "\n",
    "  # Organizing the following ops as `final_training_ops` so they're easier\n",
    "  # to see in TensorBoard\n",
    "  train_step = None\n",
    "  cross_entropy_mean = None\n",
    "\n",
    "  layer_name = 'final_training_ops'\n",
    "  with tf.name_scope(layer_name):\n",
    "    with tf.name_scope('weights'):\n",
    "      layer_weights = tf.Variable(\n",
    "          tf.truncated_normal(\n",
    "              [BOTTLENECK_TENSOR_SIZE, class_count],\n",
    "              stddev=0.001), name='final_weights')\n",
    "      # variable_summaries(layer_weights, layer_name + '/weights')\n",
    "    with tf.name_scope('biases'):\n",
    "      layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n",
    "      # variable_summaries(layer_biases, layer_name + '/biases')\n",
    "    with tf.name_scope('Wx_plus_b'):\n",
    "      logits = tf.matmul(bottleneck_input, layer_weights) + layer_biases\n",
    "      tf.histogram_summary(layer_name + '/pre_activations', logits)\n",
    "\n",
    "  final_tensor = tf.nn.softmax(logits, name=final_tensor_name)\n",
    "  tf.histogram_summary(final_tensor_name + '/activations', final_tensor)\n",
    "\n",
    "  if mode in [ModeKeys.EVAL, ModeKeys.TRAIN]:\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "      cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "          logits, ground_truth_input)\n",
    "      with tf.name_scope('total'):\n",
    "        cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "      tf.scalar_summary('cross entropy', cross_entropy_mean)\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "      train_step = tf.train.GradientDescentOptimizer(\n",
    "          ARGFLAGS.learning_rate).minimize(\n",
    "              cross_entropy_mean,\n",
    "              global_step=tf.contrib.framework.get_global_step())\n",
    "\n",
    "  return (train_step, cross_entropy_mean, final_tensor)\n",
    "\n",
    "\n",
    "def add_evaluation_step(result_tensor, ground_truth_tensor):\n",
    "  \"\"\"Inserts the operations we need to evaluate the accuracy of our results.\n",
    "  \"\"\"\n",
    "  with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "      correct_prediction = tf.equal(tf.argmax(result_tensor, 1), \\\n",
    "                                    tf.argmax(ground_truth_tensor, 1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "      evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.scalar_summary('accuracy', evaluation_step)\n",
    "  return evaluation_step\n",
    "\n",
    "\n",
    "def make_model_fn(class_count):\n",
    "\n",
    "  def _make_model(bottleneck_input, ground_truth_input, mode, params):\n",
    "\n",
    "    prediction_dict = {}\n",
    "    train_step = None\n",
    "    cross_entropy = None\n",
    "\n",
    "    # Add the new layer that we'll be training.\n",
    "    (train_step, cross_entropy,\n",
    "     final_tensor) = add_final_training_ops(\n",
    "        class_count, mode, 'final_result',\n",
    "        bottleneck_input, ground_truth_input)\n",
    "\n",
    "    if mode in [ModeKeys.EVAL, ModeKeys.TRAIN]:\n",
    "      # Create the operations we need to evaluate accuracy\n",
    "      add_evaluation_step(final_tensor, ground_truth_input)\n",
    "\n",
    "    if mode == ModeKeys.INFER:\n",
    "      predclass = tf.argmax(final_tensor, 1)\n",
    "      prediction_dict = {\"class\": final_tensor, \"index\": predclass}\n",
    "\n",
    "    return prediction_dict, cross_entropy, train_step\n",
    "\n",
    "  return _make_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to load the file that gives us the class name ordering used for the result vectors during training. (Since this info was generated from reading the photos directories structure, the ordering can potentially change.  We need to make sure that doesn't happen, so that we interpret the prediction results consistently)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the labels list, needed to create the model; if it's \n",
    "# not there, we can't proceed\n",
    "output_labels_file = os.path.join(MODEL_DIR, \"output_labels.json\")\n",
    "if gfile.Exists(output_labels_file):\n",
    "  with open(output_labels_file, 'r') as lfile:\n",
    "    labels_string = lfile.read()\n",
    "    labels_list = json.loads(labels_string)\n",
    "    print(\"labels list: %s\" % labels_list)\n",
    "    class_count = len(labels_list)\n",
    "else:\n",
    "  print(\"Labels list %s not found; we can't proceed.\" % output_labels_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Inception-based graph we'll use to generate the 'bottleneck' values. Wait for this to print \"Finished\" before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the pre-trained graph \n",
    "maybe_download_and_extract()\n",
    "graph, bottleneck_tensor, jpeg_data_tensor, resized_image_tensor = (\n",
    "    create_inception_graph())\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our custom Estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the custom estimator\n",
    "model_fn = make_model_fn(class_count)\n",
    "model_params = {}\n",
    "classifier = tf.contrib.learn.Estimator(\n",
    "    model_fn=model_fn, params=model_params, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fun, display the images that we're going to predict the classification for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If PIL/Pillow is not installed, this step is not important\n",
    "import PIL.Image\n",
    "from IPython.display import display\n",
    "for imgfile in IMAGE_PATH_LIST:\n",
    "    img = PIL.Image.open(imgfile)\n",
    "    display(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the predict() method of our Estimator to predict the classifications of our list of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_image_predictions(\n",
    "    classifier, jpeg_data_tensor, bottleneck_tensor, IMAGE_PATH_LIST, labels_list)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf27]",
   "language": "python",
   "name": "conda-env-tf27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
