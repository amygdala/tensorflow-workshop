{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... intro stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import struct\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn import ModeKeys\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "\n",
    "# If you've already downloaded the inception model, and it's elsewhere, \n",
    "# edit this path to reflect that so you don't need to re-download.\n",
    "INCEPTION_MODEL_DIR = '/tmp/imagenet'\n",
    "DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "BOTTLENECK_TENSOR_NAME = 'pool_3/_reshape:0'\n",
    "BOTTLENECK_TENSOR_SIZE = 2048\n",
    "MODEL_INPUT_WIDTH = 299\n",
    "MODEL_INPUT_HEIGHT = 299\n",
    "MODEL_INPUT_DEPTH = 3\n",
    "JPEG_DATA_TENSOR_NAME = 'DecodeJpeg/contents:0'\n",
    "RESIZED_INPUT_TENSOR_NAME = 'ResizeBilinear:0'\n",
    "\n",
    "# Edit IMAGE_PATH_LIST to specify the list of images that you'd like to \n",
    "# categorize against your trained model\n",
    "IMAGE_PATH_LIST = ['hugs_photos/hugs/9783035421_d4c6569fda.jpg',\n",
    "      'hugs_photos/hugs/9160821720_d1d926be43_b.jpg',\n",
    "      'hugs_photos/not-hugs/8855807326_18ab8a583e.jpg',\n",
    "      'hugs_photos/not-hugs/8599546166_b3c0fd6495.jpg']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace MODEL_DIR with the path to the directory in which your learned model resides.\n",
    "MODEL_DIR = '/tmp/tfmodels/img_classify/1477497910'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maybe_download_and_extract():\n",
    "  \"\"\"Download and extract the inception model tar file.\n",
    "  If the pretrained model we're using doesn't already exist, this function\n",
    "  downloads it from the TensorFlow.org website and unpacks it into a directory.\n",
    "  \"\"\"\n",
    "  dest_directory = INCEPTION_MODEL_DIR\n",
    "  if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "  filename = DATA_URL.split('/')[-1]\n",
    "  filepath = os.path.join(dest_directory, filename)\n",
    "  if not os.path.exists(filepath):\n",
    "\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' %\n",
    "                       (filename,\n",
    "                        float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()\n",
    "\n",
    "    filepath, _ = urllib.request.urlretrieve(DATA_URL,\n",
    "                                             filepath,\n",
    "                                             _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "  tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "\n",
    "\n",
    "def create_inception_graph():\n",
    "  \"\"\"\"Creates a graph from saved GraphDef file and returns a Graph object.\n",
    "  \"\"\"\n",
    "  with tf.Session() as sess:\n",
    "    model_filename = os.path.join(\n",
    "        INCEPTION_MODEL_DIR, 'classify_image_graph_def.pb')\n",
    "    with gfile.FastGFile(model_filename, 'rb') as f:\n",
    "      graph_def = tf.GraphDef()\n",
    "      graph_def.ParseFromString(f.read())\n",
    "      bottleneck_tensor, jpeg_data_tensor, resized_input_tensor = (\n",
    "          tf.import_graph_def(graph_def, name='', return_elements=[\n",
    "              BOTTLENECK_TENSOR_NAME, JPEG_DATA_TENSOR_NAME,\n",
    "              RESIZED_INPUT_TENSOR_NAME]))\n",
    "  return sess.graph, bottleneck_tensor, jpeg_data_tensor, resized_input_tensor\n",
    "\n",
    "\n",
    "def run_bottleneck_on_image(sess, image_data, image_data_tensor,\n",
    "                            bottleneck_tensor):\n",
    "  \"\"\"Runs inference on an image to extract the 'bottleneck' summary layer.\n",
    "  \"\"\"\n",
    "  bottleneck_values = sess.run(\n",
    "      bottleneck_tensor,\n",
    "      {image_data_tensor: image_data})\n",
    "  bottleneck_values = np.squeeze(bottleneck_values)\n",
    "  return bottleneck_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_image_predictions(\n",
    "    classifier, jpeg_data_tensor, bottleneck_tensor, path_list, labels_list):\n",
    "  \"\"\"Use the learned model to make predictions.\"\"\"\n",
    "\n",
    "  if not labels_list:\n",
    "    output_labels_file = os.path.join(MODEL_DIR, \"output_labels.json\")\n",
    "    if gfile.Exists(output_labels_file):\n",
    "      with open(output_labels_file, 'r') as lfile:\n",
    "        labels_string = lfile.read()\n",
    "        labels_list = json.loads(labels_string)\n",
    "        print(\"labels list: %s\" % labels_list)\n",
    "    else:\n",
    "      print(\"Labels list %s not found\" % output_labels_file)\n",
    "      return None\n",
    "\n",
    "  sess = tf.Session()\n",
    "  bottlenecks = []\n",
    "  print(\"Predicting for images: %s\" % path_list)\n",
    "  for img_path in path_list:\n",
    "    # get bottleneck for an image path. Don't cache the bottleneck values here.\n",
    "    if not gfile.Exists(img_path):\n",
    "      tf.logging.fatal('File does not exist %s', img_path)\n",
    "    image_data = gfile.FastGFile(img_path, 'rb').read()\n",
    "    bottleneck_values = run_bottleneck_on_image(sess, image_data,\n",
    "                                                jpeg_data_tensor,\n",
    "                                                bottleneck_tensor)\n",
    "    bottlenecks.append(bottleneck_values)\n",
    "  prediction_input = np.array(bottlenecks)\n",
    "  predictions = classifier.predict(x=prediction_input, as_iterable=True)\n",
    "  print(\"Predictions:\")\n",
    "  for _, p in enumerate(predictions):\n",
    "    print(p[\"class\"])\n",
    "    print(p[\"index\"])\n",
    "    print(labels_list[p[\"index\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_final_training_ops(\n",
    "    class_count, mode, final_tensor_name,\n",
    "    bottleneck_input, ground_truth_input):\n",
    "  \"\"\"Adds a new softmax and fully-connected layer for training.\n",
    "  \"\"\"\n",
    "\n",
    "  # Organizing the following ops as `final_training_ops` so they're easier\n",
    "  # to see in TensorBoard\n",
    "  train_step = None\n",
    "  cross_entropy_mean = None\n",
    "\n",
    "  layer_name = 'final_training_ops'\n",
    "  with tf.name_scope(layer_name):\n",
    "    with tf.name_scope('weights'):\n",
    "      layer_weights = tf.Variable(\n",
    "          tf.truncated_normal(\n",
    "              [BOTTLENECK_TENSOR_SIZE, class_count],\n",
    "              stddev=0.001), name='final_weights')\n",
    "      # variable_summaries(layer_weights, layer_name + '/weights')\n",
    "    with tf.name_scope('biases'):\n",
    "      layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n",
    "      # variable_summaries(layer_biases, layer_name + '/biases')\n",
    "    with tf.name_scope('Wx_plus_b'):\n",
    "      logits = tf.matmul(bottleneck_input, layer_weights) + layer_biases\n",
    "      tf.histogram_summary(layer_name + '/pre_activations', logits)\n",
    "\n",
    "  final_tensor = tf.nn.softmax(logits, name=final_tensor_name)\n",
    "  tf.histogram_summary(final_tensor_name + '/activations', final_tensor)\n",
    "\n",
    "  if mode in [ModeKeys.EVAL, ModeKeys.TRAIN]:\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "      cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "          logits, ground_truth_input)\n",
    "      with tf.name_scope('total'):\n",
    "        cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "      tf.scalar_summary('cross entropy', cross_entropy_mean)\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "      train_step = tf.train.GradientDescentOptimizer(\n",
    "          ARGFLAGS.learning_rate).minimize(\n",
    "              cross_entropy_mean,\n",
    "              global_step=tf.contrib.framework.get_global_step())\n",
    "\n",
    "  return (train_step, cross_entropy_mean, final_tensor)\n",
    "\n",
    "\n",
    "def add_evaluation_step(result_tensor, ground_truth_tensor):\n",
    "  \"\"\"Inserts the operations we need to evaluate the accuracy of our results.\n",
    "  \"\"\"\n",
    "  with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "      correct_prediction = tf.equal(tf.argmax(result_tensor, 1), \\\n",
    "                                    tf.argmax(ground_truth_tensor, 1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "      evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.scalar_summary('accuracy', evaluation_step)\n",
    "  return evaluation_step\n",
    "\n",
    "\n",
    "def make_model_fn(class_count):\n",
    "\n",
    "  def _make_model(bottleneck_input, ground_truth_input, mode, params):\n",
    "\n",
    "    prediction_dict = {}\n",
    "    train_step = None\n",
    "    cross_entropy = None\n",
    "\n",
    "    # Add the new layer that we'll be training.\n",
    "    (train_step, cross_entropy,\n",
    "     final_tensor) = add_final_training_ops(\n",
    "        class_count, mode, 'final_result',\n",
    "        bottleneck_input, ground_truth_input)\n",
    "\n",
    "    if mode in [ModeKeys.EVAL, ModeKeys.TRAIN]:\n",
    "      # Create the operations we need to evaluate accuracy\n",
    "      add_evaluation_step(final_tensor, ground_truth_input)\n",
    "\n",
    "    if mode == ModeKeys.INFER:\n",
    "      predclass = tf.argmax(final_tensor, 1)\n",
    "      prediction_dict = {\"class\": final_tensor, \"index\": predclass}\n",
    "\n",
    "    return prediction_dict, cross_entropy, train_step\n",
    "\n",
    "  return _make_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels list: [u'not hugs', u'hugs']\n"
     ]
    }
   ],
   "source": [
    "# load the labels list, needed to create the model; if it's \n",
    "# not there, we can't proceed\n",
    "output_labels_file = os.path.join(MODEL_DIR, \"output_labels.json\")\n",
    "if gfile.Exists(output_labels_file):\n",
    "  with open(output_labels_file, 'r') as lfile:\n",
    "    labels_string = lfile.read()\n",
    "    labels_list = json.loads(labels_string)\n",
    "    print(\"labels list: %s\" % labels_list)\n",
    "    class_count = len(labels_list)\n",
    "else:\n",
    "  print(\"Labels list %s not found; we can't proceed.\" % output_labels_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "# Set up the pre-trained graph \n",
    "maybe_download_and_extract()\n",
    "graph, bottleneck_tensor, jpeg_data_tensor, resized_image_tensor = (\n",
    "    create_inception_graph())\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using default config.\n"
     ]
    }
   ],
   "source": [
    "# Define the custom estimator\n",
    "model_fn = make_model_fn(class_count)\n",
    "model_params = {}\n",
    "classifier = tf.contrib.learn.Estimator(\n",
    "    model_fn=model_fn, params=model_params, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for images: ['hugs_photos/hugs/9783035421_d4c6569fda.jpg', 'hugs_photos/hugs/9160821720_d1d926be43_b.jpg', 'hugs_photos/not-hugs/8855807326_18ab8a583e.jpg', 'hugs_photos/not-hugs/8599546166_b3c0fd6495.jpg']\n",
      "Predictions:\n",
      "[  3.61323851e-04   9.99638677e-01]\n",
      "1\n",
      "hugs\n",
      "[ 0.00209123  0.99790883]\n",
      "1\n",
      "hugs\n",
      "[ 0.99897695  0.00102306]\n",
      "0\n",
      "not hugs\n",
      "[  9.99771416e-01   2.28555917e-04]\n",
      "0\n",
      "not hugs\n"
     ]
    }
   ],
   "source": [
    "make_image_predictions(\n",
    "    classifier, jpeg_data_tensor, bottleneck_tensor, IMAGE_PATH_LIST, labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf27]",
   "language": "python",
   "name": "conda-env-tf27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
