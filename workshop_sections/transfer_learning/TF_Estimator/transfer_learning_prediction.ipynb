{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook lets you run predictions against an image classification model trained with `transfer_learning.py` (and bootstrapping from the saved Inception v3 image classification model), in this same directory. See the README in this directory for more information on running the training on a set of photos first.\n",
    "\n",
    "First, some imports and definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import struct\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn import ModeKeys\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "import transfer_learning\n",
    "\n",
    "# If you've already downloaded the inception model, and it's elsewhere, \n",
    "# edit this path to reflect that so you don't need to re-download.\n",
    "INCEPTION_MODEL_DIR = '/tmp/imagenet'\n",
    "DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "BOTTLENECK_TENSOR_NAME = 'pool_3/_reshape:0'\n",
    "BOTTLENECK_TENSOR_SIZE = 2048\n",
    "MODEL_INPUT_WIDTH = 299\n",
    "MODEL_INPUT_HEIGHT = 299\n",
    "MODEL_INPUT_DEPTH = 3\n",
    "JPEG_DATA_TENSOR_NAME = 'DecodeJpeg/contents:0'\n",
    "RESIZED_INPUT_TENSOR_NAME = 'ResizeBilinear:0'\n",
    "\n",
    "LABELS_FILENAME = \"output_labels.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edit the following** to point to the model directory in which the trained model that you want to use resides.  If you just did a training run, the directory name will have been printed to STDOUT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace MODEL_DIR with the path to the directory in which your learned model resides.\n",
    "MODEL_DIR = '/tmp/tfmodels/img_classify/your-model-dir'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define some helper functions. You'll find these functions in `transfer_learning.py` also.\n",
    "\n",
    "(In `run_bottleneck_on_image`, note that we're calling `sess.run()` to get the value of the 'bottleneck' layer of the Inception graph, with image data fed to the JPEG_DATA_TENSOR_NAME node.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_inception_graph():\n",
    "  \"\"\"\"Creates a graph from saved GraphDef file and returns a Graph object.\n",
    "  \"\"\"\n",
    "  with tf.Session() as sess:\n",
    "    model_filename = os.path.join(\n",
    "        INCEPTION_MODEL_DIR, 'classify_image_graph_def.pb')\n",
    "    with gfile.FastGFile(model_filename, 'rb') as f:\n",
    "      graph_def = tf.GraphDef()\n",
    "      graph_def.ParseFromString(f.read())\n",
    "      bottleneck_tensor, jpeg_data_tensor, resized_input_tensor = (\n",
    "          tf.import_graph_def(graph_def, name='', return_elements=[\n",
    "              BOTTLENECK_TENSOR_NAME, JPEG_DATA_TENSOR_NAME,\n",
    "              RESIZED_INPUT_TENSOR_NAME]))\n",
    "  return sess.graph, bottleneck_tensor, jpeg_data_tensor, resized_input_tensor\n",
    "\n",
    "\n",
    "def run_bottleneck_on_image(sess, image_data, image_data_tensor,\n",
    "                            bottleneck_tensor):\n",
    "  \"\"\"Runs inference on an image to extract the 'bottleneck' summary layer.\n",
    "  \"\"\"\n",
    "  bottleneck_values = sess.run(\n",
    "      bottleneck_tensor,\n",
    "      {image_data_tensor: image_data})\n",
    "  bottleneck_values = np.squeeze(bottleneck_values)\n",
    "  return bottleneck_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to load the file that gives us the class name ordering used for the result vectors during training. (Since this info was generated from reading the photos directories structure, the ordering can potentially change.  We need to make sure that doesn't happen, so that we interpret the prediction results consistently)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the labels list, needed to create the model; if it's \n",
    "# not there, we can't proceed\n",
    "output_labels_file = os.path.join(MODEL_DIR, \"output_labels.json\")\n",
    "if gfile.Exists(output_labels_file):\n",
    "  with open(output_labels_file, 'r') as lfile:\n",
    "    labels_string = lfile.read()\n",
    "    labels_list = json.loads(labels_string)\n",
    "    print(\"labels list: %s\" % labels_list)\n",
    "    class_count = len(labels_list)\n",
    "else:\n",
    "  print(\"Labels list %s not found; we can't proceed.\" % output_labels_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to run the image predictions. First, we need to get the 'bottleneck' values, using the graph loaded from the Inception model. Then, we feed that data to our own trained model.\n",
    "`classifier` is a custom Estimator, and we will use its `predict` method. (We'll define the Estimator in a few more cells). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_image_predictions(\n",
    "    classifier, jpeg_data_tensor, bottleneck_tensor, path_list, labels_list):\n",
    "  \"\"\"Use the learned model to make predictions.\"\"\"\n",
    "\n",
    "  if not labels_list:\n",
    "    output_labels_file = os.path.join(MODEL_DIR, LABELS_FILENAME)\n",
    "    if gfile.Exists(output_labels_file):\n",
    "      with open(output_labels_file, 'r') as lfile:\n",
    "        labels_string = lfile.read()\n",
    "        labels_list = json.loads(labels_string)\n",
    "        print(\"labels list: %s\" % labels_list)\n",
    "    else:\n",
    "      print(\"Labels list %s not found\" % output_labels_file)\n",
    "      return None\n",
    "\n",
    "  sess = tf.Session()\n",
    "  bottlenecks = []\n",
    "  print(\"Predicting for images: %s\" % path_list)\n",
    "  for img_path in path_list:\n",
    "    # get bottleneck for an image path.\n",
    "    if not gfile.Exists(img_path):\n",
    "      tf.logging.fatal('File does not exist %s', img_path)\n",
    "    image_data = gfile.FastGFile(img_path, 'rb').read()\n",
    "    bottleneck_values = run_bottleneck_on_image(sess, image_data,\n",
    "                                                jpeg_data_tensor,\n",
    "                                                bottleneck_tensor)\n",
    "    bottlenecks.append(bottleneck_values)\n",
    "  prediction_input = np.array(bottlenecks)\n",
    "  predictions = classifier.predict(x=prediction_input, as_iterable=True)\n",
    "  print(\"Predictions:\")\n",
    "  for _, p in enumerate(predictions):\n",
    "    print(\"---------\")\n",
    "    for k in p.keys():\n",
    "      print(\"%s is: %s \" % (k, p[k]))\n",
    "      if k == \"index\":\n",
    "        print(\"index label is: %s\" % labels_list[p[k]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Inception-based graph we'll use to generate the 'bottleneck' values. Wait for this to print \"Finished\" before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the pre-trained graph \n",
    "transfer_learning.maybe_download_and_extract(INCEPTION_MODEL_DIR)\n",
    "graph, bottleneck_tensor, jpeg_data_tensor, resized_image_tensor = (\n",
    "    create_inception_graph())\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our custom Estimator. (As the lab exercise, you will write some of the code that does this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the custom estimator\n",
    "model_fn = transfer_learning.make_model_fn(class_count, 'final_result')\n",
    "model_params = {}\n",
    "classifier = tf.contrib.learn.Estimator(\n",
    "    model_fn=model_fn, params=model_params, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_list = transfer_learning.get_prediction_images('prediction_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fun, display the images that we're going to predict the classification for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If PIL/Pillow is not installed, this step is not important\n",
    "import PIL.Image\n",
    "from IPython.display import display\n",
    "for imgfile in img_list:\n",
    "    img = PIL.Image.open(imgfile)\n",
    "    display(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the predict() method of our Estimator to predict the classifications of our list of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_image_predictions(\n",
    "    classifier, jpeg_data_tensor, bottleneck_tensor, img_list, labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With the default images, you should see that the hedgehog and knife are not judged very huggable, but the puppy is!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
