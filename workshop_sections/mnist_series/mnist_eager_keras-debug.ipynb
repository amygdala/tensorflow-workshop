{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras with TensorFlow eager mode, on the 'Fashion MNIST' dataset\n",
    "\n",
    "In this notebook, we'll use [TensorFlow's new eager execution mode](https://www.tensorflow.org/programmers_guide/eager)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "WZfwoVGAa9jd",
    "outputId": "cb516ba7-baa3-41c8-e01a-91f58e23bee6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# The TF version should be >= 1.7\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "zX-y0FVXrd_l"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable eager execution for this program. Eager execution makes TensorFlow evaluate operations immediately, returning concrete values instead of creating a [computational graph](https://www.tensorflow.org/programmers_guide/graphs) that is executed later. If you are used to a REPL or the `python` interactive console, you'll feel at home.\n",
    "\n",
    "Once eager execution is enabled, it *cannot* be disabled within the same program. See the [eager execution guide](https://www.tensorflow.org/programmers_guide/eager) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xU-Wf-vVa-t8"
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.eager as tfe\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the 'Fashion MNIST' dataset, this time via the Keras `datasets` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "54FtfeNQa0_n",
    "outputId": "0ef457e2-b3aa-4a45-c684-2b204cfa3abf"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "y_train = tf.cast(y_train, tf.int32)\n",
    "y_test = tf.cast(y_test, tf.int32)\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices... e.g. based on\n",
    "# https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a CNN model using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "BNe8xG1Pr0P1",
    "outputId": "54b4a975-1d09-4600-de63-8c8a8fff1fb5"
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow's [Dataset API](https://www.tensorflow.org/programmers_guide/datasets) handles many common cases for feeding data into a model. This is a high-level API for reading data and transforming it into a form used for training. See the [Datasets Quick Start guide](https://www.tensorflow.org/get_started/datasets_quickstart) for more information.\n",
    "Datasets work with TensorFlow Eager mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "CMajrImWbAvZ"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "SHUFFLE_SIZE = 1000\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)) \\\n",
    "          .shuffle(SHUFFLE_SIZE) \\\n",
    "          .batch(BATCH_SIZE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)) \\\n",
    "          .batch(BATCH_SIZE)\n",
    "\n",
    "# View a single example entry from a batch\n",
    "features, labels = tfe.Iterator(test_dataset).next()\n",
    "# print(\"example feature:\", features[0])\n",
    "print(\"example label:\", labels[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss and gradient function\n",
    "\n",
    "Both training and evaluation stages need to calculate the model's *[loss](https://developers.google.com/machine-learning/crash-course/glossary#loss)*. This measures how off a model's predictions are from the desired label, in other words, how bad the model is performing. We want to minimize, or optimize, this value.\n",
    "\n",
    "Our model will calculate its loss using the [tf.losses.sparse_softmax_cross_entropy](https://www.tensorflow.org/api_docs/python/tf/losses/sparse_softmax_cross_entropy) function which takes the model's prediction and the desired label. The returned loss value is progressively larger as the prediction gets worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "VxmgSrb9118w"
   },
   "outputs": [],
   "source": [
    "def loss(model, x, y):\n",
    "  y_ = model(x)\n",
    "  return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
    "\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "  with tfe.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets)\n",
    "  return tape.gradient(loss_value, model.variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an optimizer\n",
    "\n",
    "An *[optimizer](https://developers.google.com/machine-learning/crash-course/glossary#optimizer)* applies the computed gradients to the model's variables to minimize the `loss` function. You can think of a curved surface (see Figure 3) and we want to find its lowest point by walking around. The gradients point in the direction of steepest ascentâ€”so we'll travel the opposite way and move down the hill. By iteratively calculating the loss and gradient for each batch, we'll adjust the model during training. Gradually, the model will find the best combination of weights and bias to minimize loss. And the lower the loss, the better the model's predictions.\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"http://cs231n.github.io/assets/nn3/opt1.gif\" width=\"70%\"\n",
    "         alt=\"Optimization algorthims visualized over time in 3D space.\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>Figure 3.</b> Optimization algorthims visualized over time in 3D space. (Source: <a href=\"http://cs231n.github.io/neural-networks-3/\">Stanford class CS231n</a>, MIT License)<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "TensorFlow has many [optimization algorithms](https://www.tensorflow.org/api_guides/python/train) available for training. This model uses the [tf.train.GradientDescentOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer) that implements the *[stochastic gradient descent](https://developers.google.com/machine-learning/crash-course/glossary#gradient_descent)* (SGD) algorithm. The `learning_rate` sets the step size to take for each iteration down the hill. This is a *hyperparameter* that you'll commonly adjust to achieve better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "i1PcGU6n18zz"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run a training loop, applying the gradients tape as defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "zNfMvIgK24qL",
    "outputId": "d1edcb3d-1d59-4508-ec54-661656eb262c"
   },
   "outputs": [],
   "source": [
    "## Note: Rerunning this cell uses the same model variables\n",
    "\n",
    "# keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  epoch_loss_avg = tfe.metrics.Mean()\n",
    "  epoch_accuracy = tfe.metrics.Accuracy()\n",
    "\n",
    "  # Training loop - using batches of BATCH_SIZE\n",
    "  for images, labels in tfe.Iterator(train_dataset):\n",
    "    # Optimize the model\n",
    "    grads = grad(model, images, labels)\n",
    "    optimizer.apply_gradients(zip(grads, model.variables),\n",
    "                              global_step=tf.train.get_or_create_global_step())\n",
    "\n",
    "    # Track progress\n",
    "    epoch_loss_avg(loss(model, images, labels))  # add current batch loss\n",
    "    # compare predicted label to actual label\n",
    "    epoch_accuracy(tf.argmax(model(images), axis=1, output_type=tf.int32), labels)\n",
    "\n",
    "  # end epoch\n",
    "  train_loss_results.append(epoch_loss_avg.result())\n",
    "  train_accuracy_results.append(epoch_accuracy.result())\n",
    "  \n",
    "#  if epoch % 50 == 0:\n",
    "  print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the training loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "bsULxWzUaziF",
    "outputId": "0b7e642a-6853-4292-aeb4-81975c814688"
   },
   "outputs": [],
   "source": [
    "# Skip this cell if you don't have matplotlib installed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_accuracy_results)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at how our model does with the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "KOW1QNKud8nh",
    "outputId": "7107ff56-7512-4126-edb1-772f0c2743c2"
   },
   "outputs": [],
   "source": [
    "test_accuracy = tfe.metrics.Accuracy()\n",
    "\n",
    "for (x, y) in tfe.Iterator(test_dataset):\n",
    "  prediction = tf.argmax(model(x), axis=1, output_type=tf.int32)\n",
    "  test_accuracy(prediction, y)\n",
    "\n",
    "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tcAPS4vVe8Lg"
   },
   "source": [
    "<hr>\n",
    "Copyright 2018 Google Inc. All Rights Reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    " http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ruV-pM0Le9G7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
